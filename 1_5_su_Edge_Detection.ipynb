{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNjTl8CixwyMw0UNEn8kuLC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DataScienceAndEngineering/machine-learning-dse-i210-final-project-signlanguageclassification/blob/sumaiya/1_5_su_Edge_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ITqm-dh7Ujot"
      },
      "outputs": [],
      "source": [
        "#import library\n",
        "import os\n",
        "import numpy as np\n",
        "import pickle\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tqdm import tqdm\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import confusion_matrix, roc_curve, auc, matthews_corrcoef, cohen_kappa_score\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FvWsLsQoUr-I",
        "outputId": "e7270e74-0312-444a-f1e5-f9cdf0287d17"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 100k shuffled data\n",
        "with open('/content/drive/Shareddrives/SignLanguageData/combined_augmented_data_v3.pkl','rb') as f:\n",
        "  X_train,y_train,X_test,y_test = pickle.load(f)\n"
      ],
      "metadata": {
        "id": "XFxigGxRUuVH"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#printing shapes \n",
        "print(f'X_train Shape: {X_train.shape}')\n",
        "print(f'y_train Shape: {y_train.shape}')\n",
        "print(f'X_test Shape: {X_test.shape}')\n",
        "print(f'y_test Shape: {y_test.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fcLAwpv4VMLn",
        "outputId": "4c2238a9-0612-42b0-f63b-80ac5f4d8d3d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train Shape: (109820, 28, 28)\n",
            "y_train Shape: (109820,)\n",
            "X_test Shape: (28688, 28, 28)\n",
            "y_test Shape: (28688,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#fuction to find the indices given a label \n",
        "def find_indices(data,label):\n",
        "    #check if data is numpy array\n",
        "    if type(data) == np.ndarray:\n",
        "        #return indices\n",
        "        return np.where(data==label)\n",
        "    #check if data is pandas series \n",
        "    elif type(data) == pd.Series:\n",
        "        #return indices\n",
        "        return data[data==label].index\n",
        "    #else not supported in this function\n",
        "    else:\n",
        "        raise Exception('Not supported data type for this function.')"
      ],
      "metadata": {
        "id": "TwUlDZClVPrW"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#letters\n",
        "letters = ['A','B','C','D','E','F','G','H','I','K','L','M','N','O','P','Q','R','S','T','U','V','W','X','Y']\n",
        "#numbers \n",
        "numbers = sorted(list(np.unique(y_train.astype(int))))\n",
        "#dictionary of labels \n",
        "labels = dict(zip(numbers,letters))"
      ],
      "metadata": {
        "id": "Qg2HxLX_VSFt"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Reshape the data to (num_samples, 784)\n",
        "# X_train = X_train.reshape(X_train.shape[0], -1)\n",
        "# X_test = X_test.reshape(X_test.shape[0], -1)\n",
        "# y_train = y_train\n",
        "# y_test = y_test\n",
        "# # Print the shapes of the augmented data\n",
        "# print(f'X_train shape: {X_train.shape}')\n",
        "# print(f'y_train shape: {y_train.shape}')\n",
        "# print(f'X_test shape: {X_test.shape}')\n",
        "# print(f'y_test shape: {y_test.shape}')"
      ],
      "metadata": {
        "id": "73HuZes9VUax"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#fuction to find the indices given a label \n",
        "def find_indices(data,label):\n",
        "    #check if data is numpy array\n",
        "    if type(data) == np.ndarray:\n",
        "        #return indices\n",
        "        return np.where(data==label)\n",
        "    #check if data is pandas series \n",
        "    elif type(data) == pd.Series:\n",
        "        #return indices\n",
        "        return data[data==label].index\n",
        "    #else not supported in this function\n",
        "    else:\n",
        "        raise Exception('Not supported data type for this function.')"
      ],
      "metadata": {
        "id": "1wibkz0yVYn_"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function to apply Canny edge detection and post-processing\n",
        "def canny_edges(img, sigma=0.33, kernel_size=3, iterations=2):\n",
        "    # Convert image to uint8 if needed\n",
        "    if img.dtype != 'uint8':\n",
        "        img = np.uint8(img)\n",
        "    \n",
        "    # Apply Gaussian blur to remove noise\n",
        "    img = cv2.GaussianBlur(img, (kernel_size, kernel_size), 0)\n",
        "    \n",
        "    # Calculate lower and upper thresholds for Canny edge detection\n",
        "    med = np.median(img)\n",
        "    lower = int(max(0, (1 - sigma) * med))\n",
        "    upper = int(min(255, (1 + sigma) * med))\n",
        "    \n",
        "    # Apply Canny edge detection\n",
        "    edges = cv2.Canny(img, lower, upper)\n",
        "    \n",
        "    # Apply morphological closing to close gaps between edges\n",
        "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
        "    edges = cv2.morphologyEx(edges, cv2.MORPH_CLOSE, kernel, iterations=iterations)\n",
        "    \n",
        "    # Return the post-processed edges\n",
        "    return edges\n"
      ],
      "metadata": {
        "id": "XiQgy7BQWE14"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply edge enhancement to the training data\n",
        "X_train_edges = np.zeros(X_train.shape)\n",
        "for i in range(X_train.shape[0]):\n",
        "    X_train_edges[i] = canny_edges(X_train[i])\n",
        "\n",
        "# Apply edge enhancement to the test data\n",
        "X_test_edges = np.zeros(X_test.shape)\n",
        "for i in range(X_test.shape[0]):\n",
        "    X_test_edges[i] = canny_edges(X_test[i])\n"
      ],
      "metadata": {
        "id": "hkns4UwpW5b-"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#printing shapes \n",
        "print(f'X_train_edges Shape: {X_train_edges.shape}')\n",
        "print(f'X_test_edges Shape: {X_test_edges.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xoFYdLRMXIce",
        "outputId": "fb5850b6-241a-449e-f855-83d94ec118a2"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train_edges Shape: (109820, 28, 28)\n",
            "X_test_edges Shape: (28688, 28, 28)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6fQDwREZX6V1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}